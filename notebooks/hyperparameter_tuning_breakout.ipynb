{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1558a5c",
   "metadata": {},
   "source": [
    "# Volume Breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from hyperopt import hp\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.breakout.volume_breakout_strat import VolumeBreakoutStrategy\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3079a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = 10 # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = \"2014-01-01\"\n",
    "END_DATE = \"2023-12-31\"\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 3\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = 1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import volume_breakout_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\", \"Exchange\"]):\n",
    "             raise ValueError(\"Ticker file missing required columns: 'Security Name', 'Exchange'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip()\n",
    "            exchange = str(row[\"Exchange\"]).strip().upper()\n",
    "            if exchange == \"BSE\":\n",
    "                return f\"{name}.BO\"\n",
    "            elif exchange == \"NSE\":\n",
    "                return f\"{name}.NS\"\n",
    "            else:\n",
    "                logger.warning(f\"Unknown exchange '{exchange}' for {name}. Skipping suffix.\")\n",
    "                return name\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting Volume Breakout Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"Volume_Breakout_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {VolumeBreakoutStrategy.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=VolumeBreakoutStrategy,\n",
    "            db_config=db_config,\n",
    "            search_space=volume_breakout_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=f\"Volume_Breakout_{RUN_TIMESTAMP}\",\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81ac242",
   "metadata": {},
   "source": [
    "# Triangle Breakout Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b74022",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from hyperopt import hp\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.breakout.triangle_breakout_strat import TriangleBreakout\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = 10 # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = \"2014-01-01\"\n",
    "END_DATE = \"2023-12-31\"\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 3\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = 1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import triangle_breakout_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\", \"Exchange\"]):\n",
    "             raise ValueError(\"Ticker file missing required columns: 'Security Name', 'Exchange'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip()\n",
    "            exchange = str(row[\"Exchange\"]).strip().upper()\n",
    "            if exchange == \"BSE\":\n",
    "                return f\"{name}.BO\"\n",
    "            elif exchange == \"NSE\":\n",
    "                return f\"{name}.NS\"\n",
    "            else:\n",
    "                logger.warning(f\"Unknown exchange '{exchange}' for {name}. Skipping suffix.\")\n",
    "                return name\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting Triangle Breakout Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"Volume_Breakout_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {TriangleBreakout.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=TriangleBreakout,\n",
    "            db_config=db_config,\n",
    "            search_space=triangle_breakout_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=f\"Volume_Breakout_{RUN_TIMESTAMP}\",\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab96cd",
   "metadata": {},
   "source": [
    "# Cup and Handle Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03372c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from hyperopt import hp\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.breakout.cup_and_handle_strat import CupAndHandle\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a4670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = 10 # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = \"2014-01-01\"\n",
    "END_DATE = \"2023-12-31\"\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 3\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = 1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import cup_and_handle_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\", \"Exchange\"]):\n",
    "             raise ValueError(\"Ticker file missing required columns: 'Security Name', 'Exchange'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip()\n",
    "            exchange = str(row[\"Exchange\"]).strip().upper()\n",
    "            if exchange == \"BSE\":\n",
    "                return f\"{name}.BO\"\n",
    "            elif exchange == \"NSE\":\n",
    "                return f\"{name}.NS\"\n",
    "            else:\n",
    "                logger.warning(f\"Unknown exchange '{exchange}' for {name}. Skipping suffix.\")\n",
    "                return name\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting Cup and Handle Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"{CupAndHandle.__name__}_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {CupAndHandle.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=CupAndHandle,\n",
    "            db_config=db_config,\n",
    "            search_space=cup_and_handle_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=experiment_name,\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading-system-u4iDTrLv-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
