{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db40a553",
   "metadata": {},
   "source": [
    "# CCI Oscillator Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Optional\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.mean_reversion.cci_oscillator_strat import CCIStrategy\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca4d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = None # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = (datetime.now() - timedelta(days=4*365)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 5\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = -1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import cci_oscillator_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\"]):\n",
    "            raise ValueError(\"Ticker file missing required columns: 'Security Name'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip().upper()\n",
    "            # Fetch company information using yfinance\n",
    "            stock = yf.Ticker(name)\n",
    "            exchange = str(stock.info.get(\"exchange\", None)).strip().upper()\n",
    "            return f\"{name}\"\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting CCI Oscillator Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"CCI_Oscillator_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {CCIStrategy.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=CCIStrategy,\n",
    "            db_config=db_config,\n",
    "            search_space=cci_oscillator_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=f\"CCI_Oscillator_{RUN_TIMESTAMP}\",\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec595964",
   "metadata": {},
   "source": [
    "# Disparity Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb14ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Optional\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.mean_reversion.disparity_index_strat import DisparityIndexStrategy\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b13b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = None # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = (datetime.now() - timedelta(days=4*365)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 5\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = -1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import disparity_index_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\"]):\n",
    "            raise ValueError(\"Ticker file missing required columns: 'Security Name'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip().upper()\n",
    "            # Fetch company information using yfinance\n",
    "            stock = yf.Ticker(name)\n",
    "            exchange = str(stock.info.get(\"exchange\", None)).strip().upper()\n",
    "            return f\"{name}\"\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting Disparity Index Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"Disparity_Index_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {DisparityIndexStrategy.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=DisparityIndexStrategy,\n",
    "            db_config=db_config,\n",
    "            search_space=disparity_index_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=f\"Disparity_index_{RUN_TIMESTAMP}\",\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d62d03",
   "metadata": {},
   "source": [
    "# Relative Strength Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Optional\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.mean_reversion.relative_strength_index_strat import RSIStrategy\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832cb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = None # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = (datetime.now() - timedelta(days=4*365)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 3\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = -1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import relative_strength_index_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\"]):\n",
    "            raise ValueError(\"Ticker file missing required columns: 'Security Name'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip().upper()\n",
    "            # Fetch company information using yfinance\n",
    "            stock = yf.Ticker(name)\n",
    "            exchange = str(stock.info.get(\"exchange\", None)).strip().upper()\n",
    "            return f\"{name}\"\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting Disparity Index Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"Relative_Strength_index_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {RSIStrategy.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=RSIStrategy,\n",
    "            db_config=db_config,\n",
    "            search_space=relative_strength_index_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=f\"Disparity_index_{RUN_TIMESTAMP}\",\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11905a04",
   "metadata": {},
   "source": [
    "# Stochastic Oscillator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70041dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Optional\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.mean_reversion.stochastic_oscillator_strat import StochasticStrategy\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60004b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = 10 # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = (datetime.now() - timedelta(days=4*365)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 5\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = -1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import stochastic_oscillator_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\"]):\n",
    "            raise ValueError(\"Ticker file missing required columns: 'Security Name'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip().upper()\n",
    "            # Fetch company information using yfinance\n",
    "            stock = yf.Ticker(name)\n",
    "            exchange = str(stock.info.get(\"exchange\", None)).strip().upper()\n",
    "            return f\"{name}\"\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting Disparity Index Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"stochastic_oscillator_index_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {StochasticStrategy.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=StochasticStrategy,\n",
    "            db_config=db_config,\n",
    "            search_space=stochastic_oscillator_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=f\"Stochastic_Oscillator_{RUN_TIMESTAMP}\",\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e12b8",
   "metadata": {},
   "source": [
    "# Williams Percent R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50907654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main script to run hyperparameter optimization and sensitivity analysis\n",
    "for the Know Sure Thing strategy using the portfolio-based evaluation framework.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Optional\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.mean_reversion.williams_percent_r_start import WilliamsRStrategy\n",
    "    from src.optimizer.strategy_optimizer import StrategyOptimizer\n",
    "    from src.optimizer.sensitivity_analyzer import SensitivityAnalyzer\n",
    "    from src.database.config import DatabaseConfig\n",
    "except ImportError as e:\n",
    "    print(\"Error importing modules. Make sure the script is run from the project root\")\n",
    "    print(\"or the 'src' directory is in the Python path.\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097b93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single stock\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"  # Store MLflow data locally in ./mlruns\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = None # Limit tickers for faster testing, set to None to use all\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = (datetime.now() - timedelta(days=4*365)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Optimization Settings\n",
    "CV_FOLDS = 5\n",
    "MAX_EVALS = 50  # Number of hyperparameter sets to evaluate\n",
    "OPTIMIZATION_METRIC = 'harmonic_mean' # Portfolio metric to maximize (minus penalty)\n",
    "N_JOBS = -1 # Use all available CPU cores for fold evaluation within optimizer\n",
    "\n",
    "# Sensitivity Analysis Settings\n",
    "RUN_SENSITIVITY = False # Set to False to skip sensitivity analysis\n",
    "NUMERIC_PERTURBATION = 0.15 # +/- 15% for sensitivity\n",
    "SENS_SAMPLES_PER_PARAM = 5\n",
    "SENS_RANDOM_SAMPLES = 20\n",
    "\n",
    "# --- Define Search Space for Awesome Oscillator ---\n",
    "\n",
    "# Note: Hyperopt doesn't easily enforce short_period < long_period directly during sampling.\n",
    "# The optimizer will evaluate invalid combinations, and they will likely fail or perform poorly.\n",
    "# Strategy itself raises ValueError if short >= long during initialization.\n",
    "\n",
    "from src.optimizer.search_space import williams_percent_r_strat_search_space\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\"]):\n",
    "            raise ValueError(\"Ticker file missing required columns: 'Security Name'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip().upper()\n",
    "            # Fetch company information using yfinance\n",
    "            stock = yf.Ticker(name)\n",
    "            exchange = str(stock.info.get(\"exchange\", None)).strip().upper()\n",
    "            return f\"{name}\"\n",
    "\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "\n",
    "        if not ticker_list:\n",
    "             raise ValueError(\"No tickers loaded.\")\n",
    "\n",
    "        return ticker_list\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Ticker file not found at: {file_path}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing ticker file: {e}\")\n",
    "        raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"--- Starting Williams Perecent R Index Optimization Script ---\")\n",
    "\n",
    "    # Setup MLflow\n",
    "    try:\n",
    "        mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "        logger.info(f\"MLflow tracking URI set to: {MLFLOW_TRACKING_URI}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to set MLflow tracking URI: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "        # Create MLflow experiment if it doesn't exist\n",
    "    try:\n",
    "        experiment_name = f\"Williams Percent R_index_{RUN_TIMESTAMP}\"\n",
    "        # Check if experiment exists\n",
    "        experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "        if experiment is None:\n",
    "            # Create new experiment\n",
    "            experiment_id = mlflow.create_experiment(experiment_name)\n",
    "            logger.info(f\"Created new MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        else:\n",
    "            experiment_id = experiment.experiment_id\n",
    "            logger.info(f\"Using existing MLflow experiment: {experiment_name} with ID: {experiment_id}\")\n",
    "        \n",
    "        # Set the experiment for subsequent runs\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to create or set MLflow experiment: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Load Tickers\n",
    "    try:\n",
    "        tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "    except Exception:\n",
    "        logger.error(\"Failed to load tickers. Exiting.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        # Optional: Add a check here to ensure DB connection is valid if possible\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --- Run Optimization ---\n",
    "    optimizer = None\n",
    "    best_params = {}\n",
    "    portfolio_performance_report = pd.DataFrame()\n",
    "    param_history_report = pd.DataFrame()\n",
    "\n",
    "    logger.info(f\"Initializing StrategyOptimizer for {WilliamsRStrategy.__name__}\")\n",
    "    try:\n",
    "        optimizer = StrategyOptimizer(\n",
    "            strategy_class=WilliamsRStrategy,\n",
    "            db_config=db_config,\n",
    "            search_space=williams_percent_r_strat_search_space,\n",
    "            tickers=tickers_to_run,\n",
    "            start_date=START_DATE,\n",
    "            end_date=END_DATE,\n",
    "            cv_folds=CV_FOLDS,\n",
    "            max_evals=MAX_EVALS,\n",
    "            optimization_metric=OPTIMIZATION_METRIC,\n",
    "            run_name=f\"Williams Perecent R_{RUN_TIMESTAMP}\",\n",
    "            n_jobs=N_JOBS\n",
    "            # risk_thresholds can be customized here if needed, otherwise defaults are used\n",
    "        )\n",
    "\n",
    "        logger.info(\"Starting hyperparameter optimization...\")\n",
    "        best_params, portfolio_performance_report, param_history_report = optimizer.run_optimization()\n",
    "\n",
    "        if not best_params:\n",
    "             logger.error(\"Optimization did not yield valid results. Best parameters not found.\")\n",
    "        else:\n",
    "             logger.info(\"--- Optimization Results ---\")\n",
    "             logger.info(f\"Best Parameters found:\\n{json.dumps(best_params, indent=2)}\")\n",
    "             logger.info(f\"\\nBest Portfolio Performance Report:\\n{portfolio_performance_report.to_string()}\")\n",
    "             logger.info(f\"\\nParameter History saved (see MLflow artifacts or CSV file). Head:\\n{param_history_report.head().to_string()}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred during optimization: {e}\", exc_info=True)\n",
    "        # Attempt to end MLflow run if it was started by the optimizer\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run(\"FAILED\")\n",
    "\n",
    "    # --- Run Sensitivity Analysis (Optional) ---\n",
    "    if RUN_SENSITIVITY and optimizer and best_params:\n",
    "        logger.info(\"\\n--- Starting Sensitivity Analysis ---\")\n",
    "        try:\n",
    "            analyzer = SensitivityAnalyzer(\n",
    "                strategy_optimizer=optimizer, # Reuse optimizer for its config and evaluation cache\n",
    "                base_params=best_params,\n",
    "                numeric_perturbation=NUMERIC_PERTURBATION,\n",
    "                num_samples_per_param=SENS_SAMPLES_PER_PARAM,\n",
    "                num_random_samples=SENS_RANDOM_SAMPLES,\n",
    "                parallel=True # Relies on optimizer's internal parallelization/caching\n",
    "            )\n",
    "\n",
    "            sensitivity_results_df, parameter_impact_df = analyzer.run()\n",
    "\n",
    "            if sensitivity_results_df.empty:\n",
    "                 logger.warning(\"Sensitivity analysis did not produce results.\")\n",
    "            else:\n",
    "                logger.info(\"--- Sensitivity Analysis Results ---\")\n",
    "                logger.info(f\"Sensitivity Results saved (see MLflow artifacts or CSV file). Head:\\n{sensitivity_results_df.head().to_string()}\")\n",
    "                logger.info(f\"\\nParameter Impact Report (Correlation):\\n{parameter_impact_df.to_string()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"An error occurred during sensitivity analysis: {e}\", exc_info=True)\n",
    "            if mlflow.active_run():\n",
    "                 mlflow.end_run(\"FAILED\") # End sensitivity run if it crashed\n",
    "\n",
    "    elif RUN_SENSITIVITY and (not optimizer or not best_params):\n",
    "        logger.warning(\"Skipping sensitivity analysis because optimization failed or produced no best parameters.\")\n",
    "\n",
    "\n",
    "    # Ensure any lingering run is terminated cleanly\n",
    "    # Should not be necessary if 'with mlflow.start_run()' is used correctly inside modules\n",
    "    # try:\n",
    "    #     while mlflow.active_run():\n",
    "    #         logger.info(f\"Ending lingering MLflow run: {mlflow.active_run().info.run_id}\")\n",
    "    #         mlflow.end_run()\n",
    "    # except Exception:\n",
    "    #      pass # Ignore errors during cleanup\n",
    "\n",
    "    logger.info(\"--- Script Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5fcb00",
   "metadata": {},
   "source": [
    "# Buy and Hold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trading_system/scripts/evaluate_bnh_benchmark.py\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Optional\n",
    "\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "# --- Adjust path to import from src ---\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "try:\n",
    "    from src.strategies.buy_and_hold_baseline import BuyAndHoldStrategy\n",
    "    from src.database.config import DatabaseConfig\n",
    "    from src.optimizer.performance_evaluator import PerformanceEvaluator, MetricsDict\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing modules. Ensure your PYTHONPATH is set correctly or run from project root.\")\n",
    "    print(f\"Current sys.path: {sys.path}\")\n",
    "    print(f\"Import Error: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "# Logging Configuration\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# MLflow Configuration (Optional for direct benchmark evaluation, but can be useful for tracking)\n",
    "MLFLOW_TRACKING_URI = \"file:./mlruns\"\n",
    "RUN_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "MLFLOW_EXPERIMENT_NAME = f\"Benchmark_Evaluations_{datetime.now().strftime('%Y%m%d')}\"\n",
    "RUN_MLFLOW = True # Set to False if you don't want to log this evaluation to MLflow\n",
    "\n",
    "# Data Configuration\n",
    "TICKER_FILE_PATH = \"../data/ticker.xlsx\" # Path relative to project root\n",
    "MAX_TICKERS = 10 # Limit tickers for faster testing, set to None to use all\n",
    "# Alternatively, define a specific list:\n",
    "# TICKERS_TO_EVALUATE = [\"RELIANCE.BO\", \"INFY.BO\"] # Overrides TICKER_FILE_PATH if not None\n",
    "TICKERS_TO_EVALUATE = None # Set to a list to use specific tickers, otherwise loads from file\n",
    "\n",
    "# Backtest Period\n",
    "START_DATE = (datetime.now() - timedelta(days=4*365)).strftime(\"%Y-%m-%d\")\n",
    "END_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Buy and Hold Strategy Parameters for RiskManager\n",
    "# For a \"purer\" buy-and-hold benchmark, minimize impact of RiskManager's stops/targets.\n",
    "# Set stop_loss_pct and take_profit_pct to values that are unlikely to be hit.\n",
    "# Slippage and transaction costs are still good to include for realism.\n",
    "BENCHMARK_STRATEGY_PARAMS = {\n",
    "    'stop_loss_pct': 1.0,          # Effectively no stop loss (100% loss from entry)\n",
    "    'take_profit_pct': 100.0,      # Effectively no take profit (10,000% gain from entry)\n",
    "    'trailing_stop_pct': 0.0,      # Disable trailing stop\n",
    "    'slippage_pct': 0.001,         # Example slippage\n",
    "    'transaction_cost_pct': 0.001, # Example transaction cost\n",
    "    'data_lookback': 252           # For BaseStrategy's get_historical_prices if no date range given\n",
    "}\n",
    "\n",
    "\n",
    "# --- Helper Functions (Copied from your example for consistency) ---\n",
    "def load_tickers(file_path: str, max_tickers: Optional[int] = None) -> List[str]:\n",
    "    \"\"\"Loads and formats ticker symbols from an Excel file.\"\"\"\n",
    "    logger.info(f\"Loading tickers from: {file_path}\")\n",
    "    try:\n",
    "        tickers_df = pd.read_excel(file_path)\n",
    "        # Basic validation\n",
    "        if not all(col in tickers_df.columns for col in [\"Security Name\"]):\n",
    "            raise ValueError(\"Ticker file missing required columns: 'Security Name'\")\n",
    "\n",
    "        tickers_df = tickers_df.drop_duplicates(subset=[\"Security Name\"]).reset_index(drop=True)\n",
    "\n",
    "        def add_ticker_suffix(row):\n",
    "            name = str(row[\"Security Name\"]).strip().upper()\n",
    "            # Fetch company information using yfinance\n",
    "            stock = yf.Ticker(name)\n",
    "            exchange = str(stock.info.get(\"exchange\", None)).strip().upper()\n",
    "            return f\"{name}\"\n",
    "        tickers_df[\"Ticker\"] = tickers_df.apply(add_ticker_suffix, axis=1)\n",
    "        ticker_list = tickers_df[\"Ticker\"].unique().tolist()\n",
    "        logger.info(f\"Loaded {len(ticker_list)} unique tickers.\")\n",
    "        if max_tickers and len(ticker_list) > max_tickers:\n",
    "            logger.warning(f\"Limiting tickers to {max_tickers} for this run.\")\n",
    "            ticker_list = ticker_list[:max_tickers]\n",
    "        if not ticker_list: raise ValueError(\"No tickers loaded.\")\n",
    "        return ticker_list\n",
    "    except FileNotFoundError: logger.error(f\"Ticker file not found at: {file_path}\"); raise\n",
    "    except Exception as e: logger.error(f\"Error processing ticker file: {e}\"); raise\n",
    "\n",
    "# --- Main Execution ---\n",
    "def main():\n",
    "    global RUN_MLFLOW # <--- DECLARE GLOBAL AT THE START OF THE FUNCTION\n",
    "\n",
    "    logger.info(\"--- Starting Buy and Hold Benchmark Evaluation Script ---\")\n",
    "\n",
    "    # Setup MLflow (Optional)\n",
    "    if RUN_MLFLOW: # Now RUN_MLFLOW is checked after potential global declaration\n",
    "        try:\n",
    "            mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "            experiment = mlflow.get_experiment_by_name(MLFLOW_EXPERIMENT_NAME)\n",
    "            if experiment is None:\n",
    "                experiment_id = mlflow.create_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "                logger.info(f\"Created new MLflow experiment: {MLFLOW_EXPERIMENT_NAME} with ID: {experiment_id}\")\n",
    "            else:\n",
    "                experiment_id = experiment.experiment_id\n",
    "                logger.info(f\"Using existing MLflow experiment: {MLFLOW_EXPERIMENT_NAME} with ID: {experiment_id}\")\n",
    "            mlflow.set_experiment(MLFLOW_EXPERIMENT_NAME)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to setup MLflow: {e}. Continuing without MLflow logging.\")\n",
    "            # If MLflow setup fails, we set the global RUN_MLFLOW to False\n",
    "            RUN_MLFLOW = False # This modification is now valid due to the global declaration above\n",
    "    \n",
    "    # ... (rest of the main function remains the same) ...\n",
    "\n",
    "    # Load Tickers or use defined list\n",
    "    if TICKERS_TO_EVALUATE:\n",
    "        tickers_to_run = TICKERS_TO_EVALUATE\n",
    "        logger.info(f\"Using predefined ticker list: {tickers_to_run}\")\n",
    "    else:\n",
    "        try:\n",
    "            tickers_to_run = load_tickers(TICKER_FILE_PATH, MAX_TICKERS)\n",
    "        except Exception:\n",
    "            logger.error(\"Failed to load tickers. Exiting.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    # Database Config\n",
    "    try:\n",
    "        db_config = DatabaseConfig.default()\n",
    "        logger.info(\"Database configuration loaded.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load database configuration: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # Start MLflow Run (if enabled)\n",
    "    active_mlflow_run = None\n",
    "    if RUN_MLFLOW: # This check now uses the potentially modified RUN_MLFLOW\n",
    "        try:\n",
    "            active_mlflow_run = mlflow.start_run(run_name=f\"BuyAndHold_Eval_{RUN_TIMESTAMP}\")\n",
    "            mlflow.log_param(\"strategy_class\", BuyAndHoldStrategy.__name__)\n",
    "            mlflow.log_param(\"tickers_evaluated_count\", len(tickers_to_run))\n",
    "            mlflow.log_param(\"tickers_sample\", \", \".join(tickers_to_run[:5]) + ('...' if len(tickers_to_run) > 5 else ''))\n",
    "            mlflow.log_param(\"start_date\", START_DATE)\n",
    "            mlflow.log_param(\"end_date\", END_DATE)\n",
    "            mlflow.log_params({f\"param_{k}\": v for k, v in BENCHMARK_STRATEGY_PARAMS.items()})\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to start MLflow run: {e}\")\n",
    "            active_mlflow_run = None\n",
    "\n",
    "\n",
    "    logger.info(f\"Initializing {BuyAndHoldStrategy.__name__} with params: {json.dumps(BENCHMARK_STRATEGY_PARAMS, indent=2)}\")\n",
    "    bnh_strategy = BuyAndHoldStrategy(db_config=db_config, params=BENCHMARK_STRATEGY_PARAMS)\n",
    "\n",
    "    logger.info(f\"Generating signals for BuyAndHoldStrategy from {START_DATE} to {END_DATE} for {len(tickers_to_run)} tickers.\")\n",
    "    df_bnh_results = bnh_strategy.generate_signals(\n",
    "        ticker=tickers_to_run,\n",
    "        start_date=START_DATE,\n",
    "        end_date=END_DATE,\n",
    "        initial_position=0,\n",
    "        latest_only=False\n",
    "    )\n",
    "\n",
    "    if df_bnh_results.empty:\n",
    "        logger.error(\"BuyAndHoldStrategy generated an empty DataFrame. Cannot calculate metrics.\")\n",
    "        if active_mlflow_run: mlflow.log_metric(\"evaluation_status\", 0); mlflow.end_run(\"FAILED\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    logger.info(f\"BuyAndHoldStrategy generated {len(df_bnh_results)} signal rows.\")\n",
    "\n",
    "    signals_dict_for_evaluator: Dict[str, pd.DataFrame] = {}\n",
    "    if isinstance(df_bnh_results.index, pd.MultiIndex):\n",
    "        for ticker_name, group_df in df_bnh_results.groupby(level='ticker'):\n",
    "            signals_dict_for_evaluator[ticker_name] = group_df.droplevel('ticker')\n",
    "    elif isinstance(tickers_to_run, str) or len(tickers_to_run) == 1:\n",
    "        ticker_name = tickers_to_run[0] if isinstance(tickers_to_run, list) else tickers_to_run\n",
    "        signals_dict_for_evaluator[ticker_name] = df_bnh_results\n",
    "    else:\n",
    "        logger.error(\"Unexpected format for df_bnh_results. Cannot prepare for PerformanceEvaluator.\")\n",
    "        if active_mlflow_run: mlflow.log_metric(\"evaluation_status\", 0); mlflow.end_run(\"FAILED\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    logger.info(\"Calculating portfolio metrics for the Buy and Hold benchmark...\")\n",
    "    portfolio_metrics: MetricsDict = PerformanceEvaluator.compute_portfolio_metrics(\n",
    "        signals_dict=signals_dict_for_evaluator\n",
    "    )\n",
    "\n",
    "    logger.info(\"\\n--- Buy and Hold Benchmark Portfolio Performance Metrics ---\")\n",
    "    if portfolio_metrics:\n",
    "        for metric, value in portfolio_metrics.items():\n",
    "            display_value = f\"{value:.4%}\" if any(sub in metric for sub in [\"return\", \"pct\", \"rate\", \"drawdown\"]) \\\n",
    "                            else f\"{value:.2f} days\" if \"duration\" in metric \\\n",
    "                            else f\"{value:.4f}\"\n",
    "            logger.info(f\"{metric.replace('_', ' ').title()}: {display_value}\")\n",
    "            if active_mlflow_run and pd.notna(value) and RUN_MLFLOW: # Check RUN_MLFLOW again before logging\n",
    "                 mlflow.log_metric(f\"portfolio_{metric}\", value)\n",
    "        if active_mlflow_run and RUN_MLFLOW: mlflow.log_metric(\"evaluation_status\", 1)\n",
    "    else:\n",
    "        logger.warning(\"No portfolio metrics were calculated.\")\n",
    "        if active_mlflow_run and RUN_MLFLOW: mlflow.log_metric(\"evaluation_status\", 0)\n",
    "\n",
    "    if portfolio_metrics:\n",
    "        results_df = pd.DataFrame([portfolio_metrics])\n",
    "        results_df['tickers_evaluated_count'] = len(tickers_to_run)\n",
    "        results_df['start_date'] = START_DATE\n",
    "        results_df['end_date'] = END_DATE\n",
    "        for p_name, p_val in BENCHMARK_STRATEGY_PARAMS.items():\n",
    "            results_df[f'param_{p_name}'] = str(p_val)\n",
    "\n",
    "        results_filename = f\"benchmark_bnh_metrics_{RUN_TIMESTAMP}.csv\"\n",
    "        results_df.to_csv(results_filename, index=False)\n",
    "        logger.info(f\"Benchmark metrics saved to {results_filename}\")\n",
    "        if active_mlflow_run and RUN_MLFLOW:\n",
    "            try:\n",
    "                mlflow.log_artifact(results_filename)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to log artifact {results_filename} to MLflow: {e}\")\n",
    "\n",
    "\n",
    "    if active_mlflow_run and RUN_MLFLOW: # Check RUN_MLFLOW before ending run\n",
    "        mlflow.end_run()\n",
    "\n",
    "    logger.info(\"--- Benchmark Evaluation Script Finished ---\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading-system-u4iDTrLv-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
